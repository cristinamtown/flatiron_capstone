{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letterboxd.com Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following notebook, we aim to create various recommendation systems that will recommend 5 movies to any given Letterboxd user using various methods including non-personal recommendations, Surprise and PySpark. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Database Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a quick look at the tables that are in the SQL database 'letterboxd.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![db_diagram](db_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Examination of Data and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries \n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import sqlite3\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize connection to the SQL database\n",
    "conn = sqlite3.Connection('letterboxd.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most rated films\n",
    "highest_rated = \"\"\"SELECT username, AVG(rating) as avg_rating\n",
    "FROM ratings, films\n",
    "WHERE ratings.film_id = films.lb_id\n",
    "GROUP BY username\n",
    "ORDER BY avg_rating DESC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_avg_rating = pd.read_sql(highest_rated, conn)\n",
    "\n",
    "user_avg_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(user_avg_rating, y=\"avg_rating\", title='Average Rating Per User')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any nulls and round to one decimal place\n",
    "user_avg_rating = user_avg_rating.dropna().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(user_avg_rating, x=\"avg_rating\", title='Average Rating Per User')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Personalized Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most popular, i.e. most rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most rated films\n",
    "most_rated = \"\"\"SELECT film_name, AVG(rating) as avg_rating, COUNT(film_id) as count\n",
    "FROM ratings, films\n",
    "WHERE ratings.film_id = films.lb_id\n",
    "GROUP BY film_id\n",
    "ORDER BY count DESC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_most_rated = pd.read_sql(most_rated, conn)\n",
    "top_20_most_rated = top_20_most_rated[:20]\n",
    "top_20_most_rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(top_20_most_rated, x='film_name', y='count', title='20 Most Rated Films')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_most_rated_sort = top_20_most_rated.sort_values(['avg_rating'], ascending=False)\n",
    "top_20_most_rated_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(top_20_most_rated_sort, x='film_name', y='avg_rating', \n",
    "              title='20 Most Rated Films Avergage Rating')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that of the 20 most rated films Parasite, Spirited Away, The Shining, Pulp Fiction, Eternal Sunshine of the Spotless Mind are the highest rated films. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user-user vs item-item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = \"\"\"SELECT *\n",
    "FROM ratings\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ratings = pd.read_sql(rating, conn, index_col = 'index')\n",
    "users_ratings.dropna(inplace=True)\n",
    "print(users_ratings.info())\n",
    "users_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order of columns username, film_id, rating\n",
    "users_ratings = users_ratings[['username', 'film_id', 'rating']]\n",
    "users_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries, Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "from surprise.prediction_algorithms import knns, KNNWithMeans, KNNBasic, KNNBaseline\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.prediction_algorithms import knns\n",
    "from surprise.similarities import cosine, msd, pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "data = Dataset.load_from_df(users_ratings,reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.build_full_trainset()\n",
    "print('Number of users: ', dataset.n_users, '\\n')\n",
    "print('Number of items: ', dataset.n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "train, test = train_test_split(data, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVD()\n",
    "svd.fit(train)\n",
    "predictions = svd.test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Pediction\n",
    "uid = 'ingloriousbasta'\n",
    "iid = 346746\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = svd.predict(uid, iid, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Pediction\n",
    "uid = 'ingloriousbasta'\n",
    "iid = 517828\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = svd.predict(uid, iid, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sim_cos = {'name':'cosine', 'user_based':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "basic = knns.KNNBasic(sim_options=sim_cos)\n",
    "basic.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "basic.sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions = basic.test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sim_pearson = {'name':'pearson', 'user_based':False}\n",
    "basic_pearson = knns.KNNBasic(sim_options=sim_pearson)\n",
    "basic_pearson.fit(train)\n",
    "predictions = basic_pearson.test(test)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sim_pearson = {'name':'pearson', 'user_based':False}\n",
    "knn_means = knns.KNNWithMeans(sim_options=sim_pearson)\n",
    "knn_means.fit(trainset)\n",
    "predictions = knn_means.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sim_pearson = {'name':'pearson', 'user_based':False}\n",
    "knn_baseline = knns.KNNBaseline(sim_options=sim_pearson)\n",
    "knn_baseline.fit(trainset)\n",
    "predictions = knn_baseline.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Least Square With PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.context import SQLContext\n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName('recsystem').config('spark.driver.host', 'localhost')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'letterboxd.db'\n",
    "query = 'SELECT * from ratings'\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Assign id numbers to usernames\n",
    "df = df.assign(id=(df['username'].astype('category').cat.codes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any films that have fewer than 100 ratings\n",
    "threshold = 100 # Anything that occurs less than this will be removed.\n",
    "value_counts = df['film_id'].value_counts() # Specific column \n",
    "to_remove = value_counts[value_counts <= threshold].index\n",
    "df['film_id'].replace(to_remove, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 237964 entries, 4 to 904861\n",
      "Data columns (total 5 columns):\n",
      "index       237964 non-null int64\n",
      "film_id     237964 non-null int64\n",
      "username    237964 non-null object\n",
      "rating      237964 non-null float64\n",
      "id          237964 non-null int16\n",
      "dtypes: float64(1), int16(1), int64(2), object(1)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df['film_id'] = df['film_id'].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426406    768\n",
       "406775    607\n",
       "475370    583\n",
       "326279    568\n",
       "353117    550\n",
       "459564    546\n",
       "51444     523\n",
       "404266    519\n",
       "397859    512\n",
       "95113     507\n",
       "34722     495\n",
       "460830    495\n",
       "51432     491\n",
       "422682    490\n",
       "251943    485\n",
       "240344    484\n",
       "433863    482\n",
       "444600    478\n",
       "51921     474\n",
       "149857    468\n",
       "51568     468\n",
       "51896     466\n",
       "41352     463\n",
       "259441    455\n",
       "114564    453\n",
       "424348    453\n",
       "333029    451\n",
       "312205    450\n",
       "438511    448\n",
       "171384    447\n",
       "         ... \n",
       "40276     102\n",
       "45263     102\n",
       "205114    102\n",
       "43015     102\n",
       "15077     102\n",
       "51472     102\n",
       "69453     102\n",
       "46084     102\n",
       "318913    102\n",
       "19921     102\n",
       "47062     102\n",
       "353273    102\n",
       "266628    102\n",
       "635253    102\n",
       "47345     102\n",
       "46778     102\n",
       "174195    101\n",
       "153285    101\n",
       "50953     101\n",
       "44920     101\n",
       "46263     101\n",
       "47913     101\n",
       "49886     101\n",
       "51163     101\n",
       "345176    101\n",
       "276291    101\n",
       "51470     101\n",
       "50224     101\n",
       "50390     101\n",
       "422900    101\n",
       "Name: film_id, Length: 1237, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['film_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = spark.createDataFrame(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('index', 'bigint'),\n",
       " ('film_id', 'bigint'),\n",
       " ('username', 'string'),\n",
       " ('rating', 'double'),\n",
       " ('id', 'bigint')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = movie_ratings.drop('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# split into training and testing sets\n",
    "(train, test) = movie_ratings.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[film_id: bigint, username: string, rating: double, id: bigint]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5,rank=4, regParam=0.1, userCol='id', itemCol='film_id', ratingCol='rating',\n",
    "          coldStartStrategy='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the ALS model to the training set\n",
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing appropriate library\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating',\n",
    "                                predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[film_id: bigint, username: string, rating: double, id: bigint, prediction: float]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.7441200416067888\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print('Root-mean-square error = ' + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# initialize the ALS model\n",
    "als_model = ALS(userCol='id', itemCol='film_id', \n",
    "                ratingCol='rating', coldStartStrategy='drop')\n",
    "\n",
    "# create the parameter grid                 \n",
    "params = ParamGridBuilder()\\\n",
    "          .addGrid(als_model.regParam, [0.01, 0.001, 0.1])\\\n",
    "          .addGrid(als_model.rank, [4, 10, 50]).build()\n",
    "\n",
    "\n",
    "# instantiating crossvalidator estimator\n",
    "cv = CrossValidator(estimator=als_model, estimatorParamMaps=params,evaluator=evaluator,parallelism=4)\n",
    "best_model = cv.fit(movie_ratings)    \n",
    "\n",
    "# We see the best model has a rank of 50, so we will use that in our future models with this dataset\n",
    "best_model.bestModel.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.7153673049046974\n"
     ]
    }
   ],
   "source": [
    "als = ALS(maxIter=5,rank=50, regParam=0.1, userCol='id', itemCol='film_id', ratingCol='rating',\n",
    "          coldStartStrategy='drop')\n",
    "\n",
    "# fit the ALS model to the training set\n",
    "model = als.fit(train)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating',\n",
    "                                predictionCol='prediction')\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print('Root-mean-square error = ' + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'letterboxd.db'\n",
    "query = 'SELECT * from films'\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "df_films = pd.read_sql_query(query, conn)\n",
    "\n",
    "movie_titles = spark.createDataFrame(data=df_films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(index=0, film_name='Parasite', lb_id=426406, lb_link='https://letterboxd.com//film/parasite-2019/', tmdb_id=496243, movie_tv='movie', release_year='2019', director='Bong Joon-ho'),\n",
       " Row(index=1, film_name='Joker', lb_id=406775, lb_link='https://letterboxd.com//film/joker-2019/', tmdb_id=475557, movie_tv='movie', release_year='2019', director='Todd Phillips'),\n",
       " Row(index=2, film_name='Knives Out', lb_id=475370, lb_link='https://letterboxd.com//film/knives-out-2019/', tmdb_id=546554, movie_tv='movie', release_year='2019', director='Rian Johnson'),\n",
       " Row(index=3, film_name='Pulp Fiction', lb_id=51444, lb_link='https://letterboxd.com//film/pulp-fiction/', tmdb_id=680, movie_tv='movie', release_year='1994', director='Quentin Tarantino'),\n",
       " Row(index=4, film_name='Inception', lb_id=34722, lb_link='https://letterboxd.com//film/inception/', tmdb_id=27205, movie_tv='movie', release_year='2010', director='Christopher Nolan')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def username_retriever(user_id, rating_df):\n",
    "    return rating_df.where(rating_df.id == user_id).take(1)[0]['username']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_retriever(username, rating_df):\n",
    "    return rating_df.where(rating_df.username == username).take(1)[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_retriever(movie_id, movie_title_df):\n",
    "    return movie_title_df.where(movie_title_df.lb_id == movie_id).take(1)[0]['film_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = movie_ratings.select(als.getUserCol()).distinct().limit(1)\n",
    "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "recs = userSubsetRecs.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12 Angry Men'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use indexing to obtain the movie id of top predicted rated item\n",
    "first_recommendation = recs[0]['recommendations'][0][0]\n",
    "\n",
    "# use the name retriever function to get the values\n",
    "name_retriever(first_recommendation, movie_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_five_rec(username):\n",
    "    user_id = id_retriever(username, movie_ratings)\n",
    "    recommendations = model.recommendForAllUsers(5)\n",
    "    first_five = recommendations.where(recommendations.id == user_id).collect()\n",
    "    temp = first_five[0]\n",
    "    temp = temp[1]\n",
    "    \n",
    "    print(f'First 5 Recommendations for {username}: \\n')\n",
    "    for x in range(len(temp)):\n",
    "        print(f'{name_retriever(temp[x][0], movie_titles)} | predicted score = {round(temp[x][1], 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Recommendations for 4dollarshrimp: \n",
      "\n",
      "Parasite | predicted score = 4.55\n",
      "12 Angry Men | predicted score = 4.53\n",
      "Stop Making Sense | predicted score = 4.53\n",
      "Harakiri | predicted score = 4.51\n",
      "Paris Is Burning | predicted score = 4.49\n"
     ]
    }
   ],
   "source": [
    "first_five_rec('4dollarshrimp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dashboard?\n",
    "- Website?\n",
    "- Content-based recommendation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
